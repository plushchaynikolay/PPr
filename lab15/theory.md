1) Чем в MPI реализованы параллельно выполняемые подзадачи? Как и в какой момент они запускаются? До каких пор существуют? Чем идентифицируются?

В MPI параллельное выполнение задач реализовано одновременно выполняемыми процессами. Все они запускаются при вызове команды `mpirun` (`mpiexec`). Все процессы существуют до конца выполнения параллельной программы, завершаются независимо друг от друга. Каждый процесс идентифицируется рангом, уникальным в рамках одного коммутатора.

2) Что такое коммуникатор? Как учитываются входящие в него процессы?

Коммуникатор - программный объект объединения процессов. Таблица номеров процессов и их адресов с собственным уникальным идентификатором.

3) Что делают функции MPI_Init() и MPI_Finalize()? Какую роль играют? Сколько раз могут быть вызваны?

`MPI_Init` - В результате выполнения этой функции создается группа процессов, в которую помещаются все процессы приложения, и создается область связи, описываемая предопределенным коммуникатором MPI_COMM_WORLD. Эта область связи объединяет все процессы-приложения. Процессы в группе упорядочены и пронумерованы от 0 до groupsize-1, где groupsize равно числу процессов в группе. Кроме этого, создается предопределенный коммуникатор MPI_COMM_SELF, описывающий свою область связи для каждого отдельного процесса.

`MPI_Finalize` - Функция закрывает все MPI-процессы и ликвидирует все области связи.

Функции играют роль точек синхронизации процессов. Могут быть вызваны только один раз.
